{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# IR Builder Walkthrough\n\n**Author**: Hongzheng Chen (hzchen@cs.cornell.edu)\n\nThis guide will walk you through the process of translating a Python-based\nAllo program to the internal MLIR representation. We will use the vector\naddition example to demonstrate the process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import allo\nfrom allo.ir.types import int32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Algorithm Definition\nWe can define a ``matrix_add`` function as follows. In the new frontend, we\nleverage the [parsing](https://en.wikipedia.org/wiki/Parsing) technique to\ntranslate the Python code to an MLIR program. Therefore, the first\nstep is to parse the Python code to the\n[Abstract Syntax Tree (AST)](https://en.wikipedia.org/wiki/Abstract_syntax_tree) representation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "M, N = 1024, 1024\n\n\ndef matrix_add(A: int32[M, N]) -> int32[M, N]:\n    B: int32[M, N] = 0\n    for i, j in allo.grid(M, N):\n        B[i, j] = A[i, j] + 1\n    return B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Python has a rich set of tools to support\n[reflection](https://en.wikipedia.org/wiki/Reflective_programming).\nOne of the most useful tools is the ``inspect`` module, which provides\nan API to access the source code of a Python function. We can call\n``inspect.getsource`` to get the source code of the ``matrix_add``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import inspect\n\nsrc = inspect.getsource(matrix_add)\nprint(src)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After we get the string representation of the source code, we can use\nthe ``ast`` module to parse the code to an AST. The ``astpretty`` module\ncan be used to print the AST in a human-readable format, which requires to\nbe installed through ``pip`` separately. Otherwise, you can just use\n``ast.dump`` to print the AST in raw format.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ast, astpretty\n\ntree = ast.parse(src)\nastpretty.pprint(tree, indent=2, show_offsets=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The AST is a tree structure that represents the syntactic structure of the\nsource code. Each node is an operator or an annotation in the source code.\nFor example, the ``FunctionDef`` node represents a function\ndefinition, and the ``AnnAssign`` node represents an annotated assignment statement.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We also wrap the above functions in ``allo.customize``, you can\n   directly call ``s = allo.customize(matrix_add, verbose=True)`` to obtain\n   the AST of the function. The entry point of the ``customize`` function is\n   located in [allo/customize.py](https://github.com/cornell-zhang/allo/blob/main/allo/customize.py).</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traverse the AST\nAfter obtaining the AST, we can traverse the tree node one by one to generate the IR.\nThe IR builder is inside [allo/ir/builder.py](https://github.com/cornell-zhang/allo/blob/main/allo/ir/builder.py).\nBasically, the builder is a dispatcher that maps the AST node to the corresponding\nIR builder function. For example, the ``FunctionDef`` node will be mapped to\n``ASTTransformer.build_FunctionDef``.\n\nAll the builder function are ``staticmethod`` s that take in two arguments:\nan AST context and an AST node.\nThe AST context stores necessary information used to build the IR, including:\n\n- ``ip_stack``: The stack of insertion points. The insertion point is used to\n  denote the current position of the IR builder. For example, when we are\n  building the body of a function, the insertion point is the function body.\n- ``buffers``: The dictionary that stores all the tensors in the program.\n- ``induction_vars``: The list of loop iterators, e.g., ``i``, ``j``, ``k``.\n- ``global_vars``: The global variables defined outside the user-defined function.\n- ``top_func``: The top-level function of the current program.\n\nThe first node to traverse is the ``Module`` node, which is the root of the AST.\nWe can see the ``build_Module`` function only does one thing: traverse the statements\ninside the body of the module, and recursively call ``build_stmt``.\n\n```python\n@staticmethod\ndef build_Module(ctx, node):\n    for stmt in node.body:\n        build_stmt(ctx, stmt)\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FunctionDef Node\nAnd then we meet the ``FunctionDef`` node, which is the function definition.\nThe ``build_FunctionDef`` function first creates the input and output data types\nbased on users' annotations. Then, it creates a new MLIR function operation by calling\n\n```python\nfunc_op = func_d.FuncOp(name=node.name, type=func_type, ip=ip, loc=loc)\n```\nHere, ``func_d`` is the [func](https://mlir.llvm.org/docs/Dialects/Func/) dialect defined in MLIR.\nThe ``FuncOp`` is the operation that represents a function in MLIR. The function arguments are\nexplained below:\n\n- ``name`` is the name of the function, and we directly use the AST ``FunctionDef`` node's name ``matrix_add`` as the operation name.\n- ``type`` is the ``FunctionType`` that defines the input and output types of the function.\n- ``ip`` is the insertion point of the function, which is the current insertion point of the AST context, and we can directly obtain it by calling ``ctx.get_ip()``.\n- ``loc`` is the actual line number of the function, which can be usually omitted.\n\nAfter creating the function operation, we need to create the function body. We first update the insertion point\nto the function body by calling ``ctx.push_ip(func_op.entry_block)``. Then, we traverse the function body and recursively\ncall ``build_stmt``. The function arguments are inserted into the ``buffers`` for further usage.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>You may probably notice the ``MockArg`` class. This is a mock class that is used to store the\n   function arguments, which are ``BlockArgument`` s in MLIR. It is different from other operations\n   that inherently have a ``result`` attribute. Therefore, we mock the ``BlockArgument`` to make\n   it consistent with other operations by providing a ``result`` property method.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AnnAssign Node\nNext, let's visit the ``AnnAssign`` node, which is the annotated assignment statement.\nThe ``build_AnnAssign`` function first evaluate the right hand side of the assignment statement\nby calling ``rhs = build_stmt(ctx, node.value)``. Then, it gets the user-defined type annotation\nto generate correct data types for the tensor. Please refer to [memref](https://mlir.llvm.org/docs/Dialects/MemRef/)\ndialect for more details. Similarly, we can call ``memref_d.AllocOp`` to create a new memory allocation,\nand you can see the actual ``memref.alloc`` operation in the generated MLIR code.\n\nOne more thing to mention is that what we see inside the AST is just **string**, so if we want to\nget the actual value of a literal, we need to retrieve it from the ``ctx.global_vars`` dictionary.\nFor example, the ``int32[M, N]`` generates the following annotation:\n\n```python\nslice=Index(\n  value=Tuple(\n    elts=[\n      Name(id='M', ctx=Load()),\n      Name(id='N', ctx=Load()),\n    ],\n    ctx=Load(),\n  ),\n)\n```\nWe can see the ``M`` and ``N`` are just the ``Name`` nodes, and we need to retrieve the actual value\nfrom the ``ctx.global_vars`` dictionary by calling something like ``ctx.global_vars[node.slice.value.elts[0].id]``.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### For Node\nThe next operator is the ``For`` node, which is the for-loop statement. We provide different APIs to\nsupport different loop structures, so we need to further dispatch the ``For`` node to the corresponding\nbuilder function. For example, here we use ``allo.grid``, so it will be dispatched to ``build_grid_for``.\n\nWe provide some helper functions in [allo/ir/transform.py](https://github.com/cornell-zhang/allo/blob/main/allo/ir/transform.py) to make the IR creation easier.\nIn this case, we can just call ``build_for_loops`` and pass in the bounds and the names of the loops\nto create a loop nest.\nBefore building the loop body, we need to update the insertion point:\n\n```python\nctx.set_ip(for_loops[-1].body.operations[0])\n```\nAfter calling ``build_stmts(ctx, node.body)``, we also need to recover the insertion point:\n\n```python\nctx.pop_ip()\n```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Other Nodes\nThe build process is similar for other nodes, so we will not go into them one by one.\nPlease refer to the [source code](https://github.com/cornell-zhang/allo/blob/main/allo/ir/builder.py) for more details.\nAfter building the IR, you can call ``s.module`` to see the effect.\n\nMost of the MLIR operations can be found on this [webpage](https://mlir.llvm.org/docs/Dialects/), and now\nyou can follow the definitions and add more amazing facilities to the new Allo compiler!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}